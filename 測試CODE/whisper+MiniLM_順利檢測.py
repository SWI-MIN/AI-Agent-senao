import whisper
from sentence_transformers import SentenceTransformer, util

# åˆå§‹åŒ– Whisper æ¨¡å‹
audio_model = whisper.load_model("base")

# åˆå§‹åŒ–èªæ„æ¨¡å‹
semantic_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# å®šç¾©èªæ„é—œéµå­—å’Œå‹•ä½œï¼ˆå¤šé—œéµå­—æ”¯æŒï¼‰
actions = {
    "æ’­æ”¾è²éŸ³": ["æ’­æ”¾è²éŸ³", "æ’­æ”¾éŸ³æ¨‚", "é–‹å§‹æ’­æ”¾"],
    "èªéŸ³è½‰æ–‡å­—": ["èªéŸ³è½‰æ–‡å­—", "STT", "Speech to text", "è½‰æˆæ–‡å­—"],
    "ç¾å ´äººæ•¸": ["ç¾å ´äººæ•¸", "äººæ•¸æª¢æ¸¬", "æ•¸ä¸€ä¸‹æœ‰å¤šå°‘äºº"]
}


# å°‡æ‰€æœ‰é—œéµå­—è½‰æ›ç‚ºèªæ„å‘é‡
action_embeddings = {}
for action, keywords in actions.items():
    action_embeddings[action] = [semantic_model.encode(keyword, convert_to_tensor=True) for keyword in keywords]

# è™•ç†éŸ³é »ä¸¦è½‰æ›ç‚ºæ–‡å­—
def transcribe_audio(file_path):
    result = audio_model.transcribe(file_path)
    return result["text"]

# èªæ„è­˜åˆ¥è§¸ç™¼å‹•ä½œ
def trigger_action(text):
    text_embedding = semantic_model.encode(text, convert_to_tensor=True)
    
    # è¨ˆç®—æ¯å€‹å‹•ä½œä¸‹æ‰€æœ‰é—œéµå­—çš„ç›¸ä¼¼åº¦ï¼Œå–æœ€å¤§å€¼ä½œç‚ºè©²å‹•ä½œçš„åŒ¹é…åˆ†æ•¸
    similarities = {}
    for action, embeddings in action_embeddings.items():
        max_similarity = max([util.pytorch_cos_sim(text_embedding, emb).item() for emb in embeddings])
        similarities[action] = max_similarity
    
    # æ‰¾åˆ°æœ€ç›¸ä¼¼çš„å‹•ä½œ
    best_match = max(similarities, key=similarities.get)
    confidence = similarities[best_match]
    
    print(f"èªæ„åŒ¹é…: {best_match}, ç½®ä¿¡åº¦: {confidence}")
    
    # è¨­å®šè§¸ç™¼é–¾å€¼
    if confidence > 0.5:
        if best_match == "æ’­æ”¾è²éŸ³":
            print("ğŸ”Š åŸ·è¡Œæ’­æ”¾éŸ³æ¨‚å‹•ä½œ")
            # åœ¨é€™è£¡åŠ å…¥æ§åˆ¶ç¡¬é«”æ’­æ”¾çš„ç¨‹å¼ç¢¼
        elif best_match == "èªéŸ³è½‰æ–‡å­—":
            print("ğŸ’¾ ä¿å­˜ç‚º TXT æ–‡ä»¶")
            # with open("output.txt", "w") as f:
            #     f.write(text)
        elif best_match == "ç¾å ´äººæ•¸":
            print("ğŸ“¸ å•Ÿå‹•ç›¸æ©Ÿä¸¦é€²è¡Œäººæ•¸è­˜åˆ¥")
            # åœ¨é€™è£¡åŠ å…¥ YOLO è­˜åˆ¥äººæ•¸çš„ç¨‹å¼ç¢¼
    else:
        print("âš ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„å‹•ä½œ")


# ç¯„ä¾‹åŸ·è¡Œæµç¨‹
audio_text = transcribe_audio(".\Sound\person_morespeak.m4a")
print(f"è½‰æ›æ–‡å­—: {audio_text}")
trigger_action(audio_text)
