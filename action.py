# action.py
import cv2
import inference
import pygame
import sounddevice as sd
import wave
import io

# éŒ„éŸ³å‹•ä½œ
def record_audio(file_path, duration=5, samplerate=16000):
    print("ğŸ™ï¸ é–‹å§‹éŒ„éŸ³ï¼ŒæŒ‰ Enter çµæŸ...")
    audio_data = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='int16')
    input("çµæŸéŒ„éŸ³...")
    sd.wait()
    with wave.open(file_path, 'wb') as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(samplerate)
        wf.writeframes(audio_data.tobytes())

# åŸ·è¡Œå‹•ä½œ
def perform_action(best_match, confidence, YOLO_model, audio_model):
    if confidence > 0.65: # æ­¤è™•èª¿æ•´èªéŸ³è¼¸å…¥å¯ä¿¡åº¦çš„éˆæ•åº¦
        if best_match == "æ’­æ”¾è²éŸ³":
            print("ğŸ”Š åŸ·è¡Œæ’­æ”¾éŸ³æ¨‚å‹•ä½œ")
            
            pygame.mixer.init()# åˆå§‹åŒ– pygame æ··éŸ³å™¨
            pygame.mixer.music.load("./Sound/ErsatzBossa.mp3")# è¼‰å…¥éŸ³æ¨‚æª”æ¡ˆ
            pygame.mixer.music.play()# æ’­æ”¾éŸ³æ¨‚

            # ç­‰å¾…æ’­æ”¾å®Œæˆ
            while pygame.mixer.music.get_busy():
                continue
            
            # åœæ­¢éŸ³æ¨‚ä¸¦é‡‹æ”¾è³‡æº
            pygame.mixer.music.stop()
            pygame.mixer.quit()

        elif best_match == "èªéŸ³è½‰æ–‡å­—":
            print("ğŸ¤ èªéŸ³è¼¸å…¥å¾Œå°‡æœƒå°‡æ­¤æ®µèªéŸ³è½‰æ–‡å­—ä¿å­˜")
            record_audio("./Sound/mic_input.wav")
            audio_text = inference.transcribe_audio("./Sound/mic_input.wav", audio_model)
            print(f"è½‰æ›æ–‡å­—: {audio_text}")
            print("ğŸ’¾ ä¿å­˜ç‚º TXT æ–‡ä»¶")
            with open("audio_text.txt", "w",encoding="utf-8") as f:
                f.write(audio_text)

        elif best_match == "ç¾å ´äººæ•¸":
            print("ğŸ“¸ å•Ÿå‹•ç›¸æ©Ÿä¸¦é€²è¡Œäººæ•¸è­˜åˆ¥")
            try:
                cap = cv2.VideoCapture(0) # é–‹å•Ÿæ”åƒé ­ (é€šå¸¸ 0 æ˜¯å…§å»ºæ”åƒé ­)
                if not cap.isOpened():
                    raise RuntimeError("ç„¡æ³•æ‰“é–‹æ”åƒé ­")
                # è·³éå‰ 15 å¹€
                frame_count = 0
                while frame_count < 15:
                    ret, frame = cap.read()
                    if not ret:
                        raise RuntimeError("æ“·å–åœ–ç‰‡å¤±æ•—")
                    frame_count += 1
                print("å½±åƒæ“·å–æˆåŠŸ")
                inference.people_detection(YOLO_model, frame)
            except RuntimeError as e:
                print(f"âŒ éŒ¯èª¤: {e}")
            finally:
                cap.release() # é‡‹æ”¾æ”åƒé ­è³‡æº

    else:
        print("âš ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„å‹•ä½œ")

